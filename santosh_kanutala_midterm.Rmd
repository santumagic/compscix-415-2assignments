---
title: "COMPSCIX 415.2 Homework 5/Midterm"
author: "Santosh Kanutala"
date: "7/6/2018"
output:
  html_document:
    highlight: tango
    number_sections: no
    theme: readable
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: 3
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Github location
My homework assignments can be found at   https://github.com/santumagic/compscix-415-2assignments.git

## RStudio and R Markdown
### Question: 1
As part of this question, I have loaded the required packages and added instructions for table of contents etc in the YAML header.
```{r load_packages, message=FALSE, warning=FALSE}
# Load the required packages
library(tidyverse)
library(mdsr)
library(nycflights13)
```
## The tidyverse packages
### Question: 1
Plotting - **ggplot2**  
Data munging/wrangling - **dplyr** 
Reshaping (speading and gathering) data - **tidyr**  
Importing/exporting data - **readr**  

### Question: 2
Plotting - **ggplot()** and **aes()**  
Data munging/wrangling - **select()** and **filter()**    
Reshaping (speading and gathering) data - **separate()** and **extract()**  
Importing/exporting data - **read_csv()** and **read_delim()**   

## R Basics
### Question: 1
```{r R Basics_Q1, warning=FALSE, message=FALSE}
My_data.name___is.too00ooLong <- c( 1 , 2 , 3 )
My_data.name___is.too00ooLong
```
**Answer:** Just with one change (removal of '!'), the code works.  

### Question: 2
```{r R Basics_Q2, warning=FALSE, message=FALSE}
# this is a charactor vector
my_string <- c('has', 'an', 'error', 'in', 'it')
my_string
```
### Question: 3
```{r R Basics_Q3, warning=FALSE, message=FALSE}
my_vector <- c(1, 2, '3', '4', 5)
my_vector
```
**Answer:** This is a numeric vector and with or without the single or double quotes, vector takes values.  

## Data import/export
### Question: 1
```{r R Data import/export_Q1, warning=FALSE, message=FALSE}
# Download and import the file rail_trail.txt
rail_trail.txt <- read.delim("/Users/skanutal/Documents/Santosh/Learning/Berkeley/rail_trail.txt", sep="|")
#glimpse the data from txt file
glimpse(rail_trail.txt)
```
### Question: 2
```{r R Data import/export_Q2, warning=FALSE, message=FALSE}
# Export the .txt file as csv into a different location
rail_trail_csv <- write_delim(
  rail_trail.txt, delim = '|',path = "/Users/skanutal/Documents/Santosh/Learning/Berkeley/3. Intro to DS/Assignments/rail_trail.csv"
  )
# Load the newly created csv file
rail_trail_csv_final <- read.csv(
  "/Users/skanutal/Documents/Santosh/Learning/Berkeley/3. Intro to DS/Assignments/rail_trail.csv", sep="|"
  )
# glimpse the data from the final csv file
glimpse(rail_trail_csv_final)
```

## Visualization
### Question: 1
**Answer:**  
   1. Both the categories age group and gender are plotted on same axis, which is confusing at a first glanse.  
   2. These are two seperate charts, but they look like one. The first chart is a chart with three ranges (<45,
      45 to 64, and >64), the second chart is a men vs women chart. This simple difference is not easily
      visible with how it is layed out currently.  
   3. With the way the data is currently layed out it is not clear that yes/no data points are proportions and the title should       visually be represented.  

### Question: 2
```{r R Visualization_Q2, warning=FALSE, message=FALSE, fig.align='center'}
# Reproduce the given graph
ggplot(data = diamonds, mapping = aes(x = cut, y = carat, fill = color)) + 
  geom_boxplot (position = "identity") +
  coord_flip() + 
  labs(x = "CUT OF DIAMOND", y = "CARAT OF DIAMOND")
```

### Question: 3
```{r R Visualization_Q3, warning=FALSE, message=FALSE, fig.align='center'}
# Enhancing the graph by changing the position to "dodge"
ggplot(data = diamonds, mapping = aes(x = cut, y = carat, fill = color)) + 
  geom_boxplot (position = "dodge") +
  coord_flip() + 
  labs(x = "CUT OF DIAMOND", y = "CARAT OF DIAMOND")
```

**Explanation:**
  By using position = "dodge", we can compare the individual values side by side.

## Data munging and wrangling
### Question: 1
```{r R munging and wrangling_Q1, warning=FALSE, message=FALSE}
# Finding the dataset tidy or not
table2
# It is not a tidy data, so below code makes it a tidy dataset
table2_tidy <- spread(table2, type, count)
# Display table2 in tidy way
table2_tidy
```
**Answer:**
To make this data tidy, there needs to be one observation per row, which we can achieve with a “spread”.

### Question: 2
```{r R munging and wrangling_Q2, warning=FALSE, message=FALSE}
# modify the diamonds dataset by adding an additional column
enhanced_diamonds <- diamonds %>% mutate(price_per_carat = price / carat)
```

### Question: 3
```{r R munging and wrangling_Q3, warning=FALSE, message=FALSE}
# finding the number of diamonds with price > 10000 and carat <1.5
diamond_target <- diamonds %>%
mutate (target_segment = (price > 10000 & carat < 1.5)) %>%
group_by(cut)
# finding the proportion  
diamond_target %>%
  summarise(target_propotion = (sum(target_segment)/length(target_segment))*100,
target_count = sum(target_segment))
```
**Answer:**  
As seen in the above dataset there are 485 ideal diamonds, and they comprise 2.25% of all ideal diamonds.
This makes sense, since as the diamond is more ideal, small diamonds are more expensive. Similarly, most fair
diamonds won’t have the same price as any of the others. It is interesting that very-good and premium diamonds are the same. Which implies that we are missing some other parameter, likely clarity, colour or some such variable.


## EDA

### Question: 1
```{r R EDA_Q1, warning=FALSE, message=FALSE}
# Select year and month from the dataset with default sorting order
txhousing %>% select(year,month)
#Select year and month from the dataset and finding the maximum year and month
txhousing %>% select(year,month) %>% arrange(desc(year), desc(month))
```
**Answer:**  
The data is from Jan 2000 to July 2015

### Question: 2
```{r R EDA_Q2, warning=FALSE, message=FALSE}
# total number of cities in the dataset
total_cities <- txhousing %>% select(city) %>% unique()
count(total_cities)
```
**Answer:**  
There are 46 unique cities in the dataset.

### Question: 3
```{r EDA_Q3, warning=FALSE, message=FALSE}
# arrange the volumes in descending order and find the top city
txhousing %>% arrange(desc(volume))
```
**Answer:**  
From the above dataset, Houston, in July/2015 had sales volume of $ 2.568 B.

### Question: 4
```{r EDA_Q4, warning=FALSE, message=FALSE}
# plotting the relation between listings and sales
ggplot(data = txhousing,mapping = aes(x=listings, y = sales)) +
geom_point() +
geom_smooth()
```
**Answer:**  
From the above plot, we can assume that the sales are incresing along with the number of listings.

### Question: 5
```{r EDA_Q5, warning=FALSE, message=FALSE}
# finding the cities with valid sales
valid_cities <- txhousing %>%
mutate(valid_sales = !is.na(sales)) %>%
group_by(city)
valid_cities # show valid cities
# finding the proportions
proportions_cities <- valid_cities %>%
summarize(proportion = round(1 - sum(valid_sales)/length(valid_sales),4)) %>%
arrange(desc(proportion))
proportions_cities # city proportions
```
### Question: 6

Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work.
  
```{r EDA_Q6.1, warning=FALSE, message=FALSE}
# cities above 500 summarise by volume
txhousing %>% group_by(sales > 500) 

# cities above 500 distributions
cities_above500 <- txhousing %>% filter(sales > 500)
ggplot(data = cities_above500, mapping = aes(x = reorder(city,median,mean), y = median)) +
  geom_boxplot() +
  labs(x = 'Cities', y = 'Median Sale Price') + 
  coord_flip() + 
  theme_dark()
```
**Answer:** 
From the graph above interestingly we can observe that the median price is higher compared to other cities  
San Antonio  
El Paso  
Austin  

Any cities that stand out that you’d want to investigate further?  

```{r EDA_Q6.2, warning=FALSE, message=FALSE}
cities_above500_outliers <- txhousing %>% filter(sales > 500)
ggplot(data = cities_above500, mapping = aes(x = reorder(city,median,mean), y = median)) +
  geom_boxplot() +
  labs(x = 'Cities', y = 'Median Sale Price') + 
  coord_flip() + 
  theme_bw()
```
**Answer:** 
By the above plaot we can conclude that the following cities with lots of outliers needs to be investigated.  
Denton County  
Dallas  
Houston  

Why might we want to filter out all cities and months with sales less than 500?

```{r EDA_Q6.3, warning=FALSE, message=FALSE}

```
**Answer:** 

## Git and Github
**Answer:** Git hub location is added in the front page of this document







